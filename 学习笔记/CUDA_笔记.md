# CUDA



[TOC]



#### CUDA简介

​	CUDA(Compute Unifide Device Architecture):是英伟达公司(nVIDIA)2006年11月提吃的一种通用并行的架构(应用于计算密集型,SIMD)，是一种通用并行计算平台和编程模型。是随着多核CPU和众核GPU的出现，而出现的新的并行程序架构。

​	CUDA设计为支持多种编程语言和应用程序接口！CUDA是在底层API的基础上，封装了一层，使得程序员可以使用C语言来方便的编程。

​	CUDA还支持C++/Python等更高级的语言编程；

​	此外，nVIDIA还提供了CuDNN，TensorRT，NPP等更高级的库函数。

​	==CUDA==(Compute Unified Device Architecture，计算机统一设备架构)，竞争对手OpenCL(from 2008，苹果公司)。

​	CUDA是nVIDIA专有的，即只能用nVIDIA的GPU。

​	OpenCL是所有nVIDIA主流媒介采用的一种标准，OpenCL可以在所有平台(nVIDIA,AMD等)执行，但是能否具有好的运行效果会有差异，同一时刻CUDA更快，CUDA未来会比OpenCL发展更快。



#### 计算能力(Compute Capability)

​	所谓计算能力(Compute Capability)，说白了就是GPU的版本号。有时也被称作SM Version。不同版本的GPU具有不同的特性，因此程序编写也会有所差异。计算能力为X，Y，其中X代表架构，Y代表次版本号。



#### 英伟达GPU系列



#### 可扩展的编程模型

​	CUDA的编程模型，使得同一个CUDA程序，可以在不同的显卡上运行。如图所示，CUDA程序会创建一些线程块(Block)，线程块会被调度到空闲的==流处理簇(SM)==上去。当线程执行完毕后，线程块会退出SM，释放出SM的资源，以供其他待执行线程块调度进去。

​	因此，无论是只有两个SM的GPU，还是有4个SM的GPU，这些线程块都会被调度执行，只不过执行的时间有长有短。

​	GPU在编程时被称为设备(device)端，CPU被称为主机(host)端

​	GPU段代码需要以核函数的形式加载，执行在GPU设备端



#### 线程层级

​	在讲内核函数前，先讲解一下线程层级。CUDA编程时一个多线程编程，数个线程(Thread)组成一个线程块(Block)，所有线程块组成一个线程网格(Grid)，图中的线程块，以及线程块的线程，是按照二维的方式排布的。实际上，CUDA编程模型允许使用一维、二维、三维三种方式来排布。

​	另外，即使线程块使用的是一维排布，线程块中的线程也不一定要按照一维排，而是可以任意排布。

​	目前的GPU限制一个线程块中，最多可以安排1024个线程。一个线程块用多少线程，以及一个线程网格用多少线程块，是程序员可以自由安排的。==由于32个相邻的线程会组成一个线程束(Tread Wrap)，而一个线程束中的线程会运行同样的指令==

​	因此一般线程块中线程的数量被安排为32的倍数，选用256是比较合适的。在线程数定下来之后，一般根据数据的排布情况来确定线程块的个数(一维排列256，二维排列(16,16))

​	例如：一个数组的长度为4096，安排每个线程处理一个元素。如果安排一个线程块为256个线程，则需要4096/256=16个线程块



#### 内核函数(Kernels)

​	内核函数是CUDA__每个线程__执行的函数，它运行在GPU设备上。CUDA使用扩展的C语言编写内核函数，关键字为\_\__global\_\__。内核函数返回值只能是void。定义格式：

```
__global__ void 函数名 (参数......)
{
	指令集和
}
```

​	主函数的调用格式：

```
函数名 <<<blocksPerGrid, threadsPerBlock>>>(参数...)
```

​	blocksPerGrid：每个网格中进程块的排布方式(可以采用一维或二维)

​	threadsPerBlock：每个进程块中进程的排布方式(可以采用一维或二维)

1. 多个thread集结成一个block，多个bolck集结成一个grid。

2. 一个block里面的线程数，以及一个grid里面的block数完全是由编程人员去决定的，但是数量的多少和排布方式会根据不同问题产生不同的效果，同时会影响到运行的效率，所以这是GPU优化速度的一个关键因素(==计算线程和数据的对应关系也不同==)

3. block里面的thread可以以1d，2d，3d的方式进行排布；grid里面的block也可以以1d，2d，3d的方式进行排布。

4. 每个核函数都可以通过预定义的变量名称去访问各个线程，如threadidx，blockidx，blockDim，gridDim的(.x,.y)分量

5. 线程块，网格的设定需要用<<<gridset, blockset>>>括起来。

6. 内建类型dim3可以设定grid或block里面二维，三维的结构模型，如dim3 BLOCKs(2，2)

7. 核函数前面需要加\_\_global\_\_进行限定，并且必须是没有返回值的void函数

8. 主机端函数可以是C++的，但是kernel中必须是C的，而且很多C中字符串相关的函数在目前来说都不能使用

   SIMT：==相同指令，不同线程==

   

   ==疑问，ppt和word上写的blockDim.x的方向不一样。。。==

#### 内存层级

​	同CPU一样，GPU也有不同层级的内存。越靠近核心的内存速度越快，但容量越小；反之，越远离核心的内存速度越慢，但容量较大。

 1. ==主机端内存(host memory)==

    指的就是我们常说的内存，一般主机端内存通过PCI-E总线与设备端测i村交换数据。数据交换的速度等于PCI-E总线的速度。

 2. ==GPU的全局内存(global memory)、常量内存(constantly memory)、纹理内存(text memory)、本地内存(local memory)==

    都位于GPU板上，但不在片内。因此速度相对于片内内存较慢。常量内存和纹理内存对于GPU来说是只读的。

	3. ==GPU上有L2 cache 和 L1 cache==

    其中L2 cache为所有流处理簇(SM)共享，而L1 cache为每个SM内部共享。这里的cache和CPU的cache一样，程序员无法对cache显式操纵。

	4. ==纹理缓存和常量缓存再SM内部共享==

    在早期1.x计算能力的时代，这两种缓存是片上唯一的缓存，十分宝贵。而当Fermi架构出现后，普通的全局内存也具有了缓存，因此就不那么突出了。

	5. ==共享内存(shared memory,SMEM)==

    具有和L1缓存同样的速度，且可以被程序员显式操纵，因此经常被用作存放一些需要反复使用的数据。共享内存只能在SM内共享，且对于CUDA编程模型来说，即使线程块被调度到了同一个SM内页无法相互访问。

	6. ==GPU的寄存器(registers)==

    和CPU不一样，其空间非常巨大，以至于可以为每一个线程分配一块dulling的寄存器空间。因此，不像CPU那样切换进程时需要保存上下文，GPU只需要修改一下寄存器空间的指针即可继续运行。所有巨大的寄存器空间，使得GPU上线程切换成为了一个几乎无损的操作。

    <font color = 'sky blue'>不过有一点需要注意，寄存器的空间不是无限大的。</font>
    
    

|                         |                            |
| ----------------------- | -------------------------- |
| 寄存器(register)        | 每个线程独有，可读可写     |
| 共享内存(shared memory) | 每个block独有，可以可写    |
| 全局显存(global memry)  | 任何线程都可以访问读写     |
| 常量显存                | 任何线程都可访问，只读     |
| 纹理显存                | 任何线程都可访问，可读可写 |

<font color = "dark red">注意事项：</font>

1. 寄存器和本地内存绑定到了每个线程，其他线程无法访问。
2. 同一个线程块内的线程，可以访问同一块共享内存。即使两个线程块调度到了同一个SM上，他们的共享内存也是隔离开的，不能互相访问。
3. 网格中的所有线程都可以自由读写全局内存。
4. 常量内存和纹理内存只能被CPU端修改，GPU内的线程只能读取数据。

#### CPU/GPU混合编程

​	一种最简单的CPU/GPU混合编程方式。程序运行额环境：

​	<font color = "marroon">主机端 (Host，即CPU执行的串行代码)</font>

​	<font color = "marroon">设备端 (Device，即GPU执行的并行代码)</font>

​	CPU和GPU的内存是独立的。因此在运行内核函数前，主机端需要调用内存拷贝函数，将数据通过PCI-E总线拷贝至设备端。内核运行结束后，需要CPU再次调用内存拷贝函数，将数据拷贝回主机端内存。

# CUDA并行编程

​	cuda c是对c/c++进行拓展后形成的编程，对c/c++兼容，文件类型为'.cu'，编译器为nvcc。cuda c允许用内核函数来扩展c，调用时由N个不同的线程共执行N次。块内的线程通过共享存储器共享数据并通过他们的执行力来协调存储器访问，aka通过调用_syncthreads()内部函数来指定内核中的同步点。

​	相比传统的cpp，添加了以下几个方面：

​	<font color="sky blue">1)函数类型限定符</font>

​	<font color="sky blue">2)执行配置运算符</font>

​	<font color="sky blue">3)五个内置变量</font>

​	<font color="sky blue">4)变量类型限定符</font>

​	<font color="sky blue">5)其他的还有数学函数，原子函数，纹理函数，绑定函数等</font>

​	

#### 函数类型限定符

​	用来确定是在CPU还是在GPU运行，以及这个函数是从CPU还是从GPU调用

|                                             |                                            |
| :------------------------------------------ | ------------------------------------------ |
| <font color="marroon">\_\_device\_\_</font> | 表示从GPU调用，在GPU运行                   |
| <font color="marroon">\_\_globa\_\_</font>  | 表示从CPU调用，在GPU执行，也称kernel核函数 |
| <font color="marroon">\_\_host\_\_</font>   | 表示在CPU上调用，在CPU上执行               |

#### 执行配置运算符

​	用来传递核函数的执行参数。使用\_\_global\_\_声明说明符定义内核用<<<...>>>来为内核指定cuda线程数。每一个线程都有一个唯一的ID，可以通过内置threadIdx(x,y)、blockIdx(x,y)、blockDim(x,y)来访问。<<<...>>>中可以是int(通过dim定义)或者dim3类型。