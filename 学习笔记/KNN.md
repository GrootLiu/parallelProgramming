# kNN(k-nearest neighbors)

### 第一种：分类

​	针对测试样本Xu，想要知道它属于那个分类，就先for循环所有**训练样本**找出Xu最近的K个邻居，然后判断这K个邻居中，大多数属于哪个类别，就将该类别作为测试样本的预测结果。

### 第二种：回归

​	根据样本点，描绘出一条曲线，使得样本点的误差最小，然后给定任意坐标，返回该曲线上的值，叫做回归

​	你有一系列样本坐标，然后给定一个测试点坐标x，求回归曲线对应的y值。用kNN的话，最简单的做法就是取k个离x最近的样本坐标，然后对他们的y值求平均。



### 算法思路

​	kNN算法的基础是对给定的query点集，对应查找在参考空间中距离最近的K个紧邻点。

​	kNN算法存在的一个重要问题是，繁重的计算量。如果参考空间由M个点，query点集有N个点，空间维度d维，那么计算query点集与参考空间各个点集的距离就有O(mnd)的时间复杂度，仅仅排序就要有O(m\*n\*logm)的时间复杂度。因此，整个kNN问题的时间复杂度为O(mnd)+O(mnlogm)。



### 算法原理

- 通用步骤
  - 计算距离（常用欧几里得距离或马氏距离）
  - 升序排序
  - 取前k个
  - 加权平均
- K的选取
  - K太大：导致分类模糊
  - K太小：受个例影响
- 然后选取K
  - 经验
  - 均方根误差